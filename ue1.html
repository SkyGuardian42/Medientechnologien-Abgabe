<!DOCTYPE html>
<html lang="de">

<head>
    <title></title>
    <link rel="stylesheet" type="text/css" href="format.css">
    <link rel="shortcut icon" href="./favicon.ico" />
    <link rel="stylesheet" href="./prism/prism.css">
    <script src="./charts/Chart.min.js"></script>
</head>

<body class="page">

    <div class="main">

        <!--Aufgabe 1-->

        <article id="a1">
            <h2>Aufgabe 1: Audiodateien erzeugen und einlesen</h2>


            <h3>
                <div class="list-indicator">1A</div> Audio-Files zuschneiden
            </h3>

            <div class="task-description">Schneide aus den dir zugeschickten Audio-Files ab dem Zeitpunkt jeweils ein Stück mit der Länge 5 Sekunden und speichere dieses als WAV-Datei ab. Parameter für Musik: fa=44,1 kHz, stereo, für Sprache: fa=8 kHz mono, beide 16 bit Auflösung.
                Beim Schneiden achtest du darauf, dass der Schnitt am Beginn einer musikalischen Figur bzw. eines Satzes liegt.
            </div>

            <p>Parameter für Musik: fa=44,1 kHz, stereo, 16 Bit Auflösung:</p>
            <audio controls>
				<source src="./audio/Musik_GroRieJa.wav" type="audio/wav">
			</audio>
            <p>Parameter für Sprache: fa=8 kHz (entsprechend stumpfer), mono, 16 Bit Auflösung:</p>
            <audio controls>
				<source src="./audio/Sprache_GroRieJa.wav" type="audio/wav">
			</audio>

        </article>

        <article>
            <h3>
                <div class="list-indicator">1B</div> Abtastfrequenzen
            </h3>
            <div class="task-description">Erkläre, warum die Audio-Files unterschiedliche Abtastfrequenzen haben.</div>

            <p>Die Sprachaufnahmen kann mit einer viel niedrigeren Abtastfrequenz gespeichert werden, da die Aufnahme dabei noch komplett verständlich bleibt. Bei dem Musikstück ist dies nicht der Fall. Hier würden bei einer Konvertierung zu 5 kHz die einzelnen
                Instrumente zum Teil verloren gehen. Die Aufnahme würde sich “Dumpf” anhören und die Instrumente wären nicht mehr zu unterscheiden.</p>

        </article>

        <article>
            <h3>
                <div class="list-indicator">1C</div> Headerangaben
            </h3>
            <div class="task-description">Lies die Musik- und die Sprachdatei mit wave_io ein und erkläre die Angaben im Header!
            </div>
            <h4>Musik</h4>
            <table>
                <tr>
                    <th>Angaben</th>
                    <th>Erklärung</th>
                </tr>
                <tr>
                    <td>Channels: 2 </td>
                    <td>Die Musik wurde als Stereo Datei gespeichert, deswegen hat die Datei 2 Channel</td>
                </tr>
                <tr>
                    <td>Frames: 223333</td>
                    <td>Anzahl der Frames innerhalb der Datei liegt bei 223 333 Stück</td>
                </tr>
                <tr>
                    <td>Sample Rate: 44100</td>
                    <td>Bei dieser Datei liegt die Abtastrate bei 44kHz</td>
                </tr>
                <tr>
                    <td>Valid Bits: 16</td>
                    <td>Es gibt 16 gültige Bits</td>
                </tr>
                <tr>
                    <td>Bytes per sample: 2</td>
                    <td>Die Anzahl der verwendeten Bytes pro Sample</td>
                </tr>
            </table>

            <h4>Sprache</h4>
            <table>
                <tr>
                    <th>Angaben</th>
                    <th>Erklärung</th>
                </tr>
                <tr>
                    <td>Channels: 1</td>
                    <td>Die Sprache wurde als Mono Datei gespeichert, deswegen hat sie nur 1 Channel</td>
                </tr>
                <tr>
                    <td>Frames: 40003</td>
                    <td>Anzahl der Frames innerhalb der Datei liegt bei 40 003 Stück</td>
                </tr>
                <tr>
                    <td>Sample Rate: 8000</td>
                    <td>Bei dieser Datei liegt die Abtastrate bei 8kHz</td>
                </tr>
                <tr>
                    <td>Valid Bits: 16</td>
                    <td>Es gibt 16 gültige Bits</td>
                </tr>
                <tr>
                    <td>Bytes per sample: 2</td>
                    <td>Die Anzahl der verwendeten Bytes pro Sample</td>
                </tr>
            </table>

        </article>

        <article>
            <h3>
                <div class="list-indicator">1D</div> Bitrate berechnen
            </h3>

            <div class="task-description">Berechne die Bitrate für die beiden Dateien!</div>

            <p>Rechenbeispiel:</p>
            <p>Bitrate = Kanäle x Samplerate x Auflösung Eine WAV-Datei in CD-Qualität hat folgende Bitrate:</p>
            <code>2 Kanäle x 16 Bit x 44,1 kHz = 1411,2 kBit/s</code>

            <table>
                <tr>
                    <th>Musik</th>
                    <td>
                        <div class="math">= 2 Kanäle * 16 Bit * 44,1 kHz = 1411,2 kBit/s</div>
                    </td>
                </tr>
                <tr>
                    <th>Sprache</th>
                    <td>
                        <div class="math">= 1 Kanal * 16 Bit * 8 kHz = 128 kBits/s</div>
                    </td>
                </tr>
            </table>
        </article>

        <!--Aufgabe 2-->

        <article id="a2">
            <h2>Aufgabe 2: Aliasing</h2>

            <p>Wir haben für die 2. Aufgabe 2 WAV-Dateien bekommen mit denen wir im Folgenden arbeiten:</p>

            <p>sine_hi02.wav</p>
            <audio controls>
				<source src="./audio/sine_hi02.wav" type="audio/wav">
			</audio>

            <p>sine_lo02.wav</p>
            <audio controls>
				<source src="./audio/sine_lo02.wav" type="audio/wav">
			</audio>

            <h3>
                <div class="list-indicator">2A</div> wave_io modifizieren
            </h3>

            <div class="task-description">Modifiziere wave_io dahingehend, dass die Samples in der WAV-Datei in eine (lesbare) ASCIIDatei geschrieben werden. Lies die von mir geschickten Sinusdateien (Sampling-Frequenz: 16 kHz) ein und bestimme aus den resultierenden Zahlenfolgen
                in der ASCII-Datei die Frequenz der Sinus Schwingungen. Begründe!</div>

            <p>Mit folgendem Code schreiben wir die WAV-Dateien in lesbare ASCII-Dateien:</p>

            <pre><code class="language-java">
				PrintWriter writer = new PrintWriter("ascii-samples.txt", "UTF-8");

				// 2a Samples schreiben
				for (int i = 0; i &lt; samples; i++) { 
					writer.println(readWavFile.sound[i]); 
				} 
					
				writer.close();</code>
			</pre>
            <p>Anschließend bestimmen wir aus den resultierenden Zahlenfolgen der Textdatei die Frequenz der Sinus Schwingungen der beiden Audio Files:</p>

            <h4>sinus_hi</h4>

            <canvas id="sine_hi02"></canvas>

            <script>
                var ctx = document.getElementById('sine_hi02').getContext('2d');
                var chart = new Chart(ctx, {
                    type: 'line',

                    // The data for our dataset
                    data: {
                        labels: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79],
                        datasets: [{
                            label: 'Samplingpunkte sine_hi02.wav',
                            backgroundColor: false,
                            fill: false,
                            borderColor: 'rgb(255, 99, 132)',
                            data: [14449, -1606, -12665, 15679, -4756, -10394, 16305, -7723, -7723, 16305, -10394, -4756, 15679, -12665, -1606, 14449, -14449, 1606, 12665, -15679, 4756, 10394, -16305, 7723, 7723, -16305, 10394, 4756, -15679, 12665, 1606, -14449, 14449, -1606, -12665, 15679, -4756, -10394, 16305, -7723, -7723, 16305, -10394, -4756, 15679, -12665, -1606, 14449, -14449, 1606, 12665, -15679, 4756, 10394, -16305, 7723, 7723, -16305, 10394, 4756, -15679, 12665, 1606, -14449, 14449, -1606, -12665, 15679, -4756, -10394, 16305, -7723, -7723, 16305, -10394, -4756, 15679, -12665, -1606, 14449]
                        }]
                    },
                    options: {}
                });
            </script>

            <p>Rechnung:</p>
            <p>16000 Samples pro Sekunde * Dauer bis gleicher Punkt erreicht, hier durch Ablesen ~3</p>
            <div class="math">s := (1/16000)*3</div>
            <div class="math">s = 0,0001875s</div>
            <p>Um in Herz umzurechnen:</p>
            <div class="math">h := 1/s</div>
            <div class="math">h = 5333,33Hz</div>

            <h4>sinus_lo</h4>

            <canvas id="sine_lo2"></canvas>
            <!--Für Malte: Hier Grafik-->
            <script>
                var ctx = document.getElementById('sine_lo2').getContext('2d');
                var chart = new Chart(ctx, {
                    type: 'line',

                    // The data for our dataset
                    data: {
                        labels: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79],
                        datasets: [{
                            label: 'Samplingpunkte sine_lo2.wav',
                            backgroundColor: false,
                            fill: false,
                            borderColor: 'rgb(75, 208, 244)',
                            data: [7723, 16305, 10394, -4756, -15679, -12665, 1606, 14449, 14449, 1606, -12665, -15679, -4756, 10394, 16305, 7723, -7723, -16305, -10394, 4756, 15679, 12665, -1606, -14449, -14449, -1606, 12665, 15679, 4756, -10394, -16305, -7723, 7723, 16305, 10394, -4756, -15679, -12665, 1606, 14449, 14449, 1606, -12665, -15679, -4756, 10394, 16305, 7723, -7723, -16305, -10394, 4756, 15679, 12665, -1606, -14449, -14449, -1606, 12665, 15679, 4756, -10394, -16305, -7723, 7723, 16305, 10394, -4756, -15679, -12665, 1606, 14449, 14449, 1606, -12665, -15679, -4756, 10394, 16305, 7723]
                        }]
                    },
                    options: {}
                });
            </script>

            <p>Rechnung:</p>
            <p>16000 Samples pro Sekunde * Dauer bis gleicher Punkt erreicht, hier durch Ablesen ~6</p>
            <div class="math">s := (1/16000)*6</div>
            <div class="math">s = 0,000375</div>
            <p>Um in Herz umzurechnen:</p>
            <div class="math">h := 1/s</div>
            <div class="math">h = 2666,66Hz</div>
        </article>

        <article>
            <h3>
                <div class="list-indicator">2B</div> Schätzung mit Spektralanalyse-Tool GRAM prüfen
            </h3>

            <div class="task-description">Überprüfe deine Schätzung mit dem Spektralanalyse-Tool GRAM.</div>

            <div class="aside">
                <div>
                    <img src="./pics/sine_hi.png" alt="sine_hi GRAM">
                </div>
                <div class="center">
                    sine_hi02.wav besteht aus einem konstanten Sinuston mit 5,5kHz.
                </div>
            </div>

            <div class="aside">
                <div>
                    <img src="./pics/sine_lo.png" alt="sine_lo GRAM">
                </div>
                <div class="center">
                    sine_lo02.wav besteht aus einem konstanten Sinuston mit 2,5kHz.
                </div>
            </div>
        </article>

        <article>
            <h3>
                <div class="list-indicator">2C</div> Abtasttheorem
            </h3>

            <div class="task-description">Bei der zeitlichen Diskretisierung eines Analogsignals muss das sogenannte Abtasttheorem eingehalten werden. Wie lautet es und wie lässt sich der Grenzfall, für den es gerade noch gilt, illustrieren? Erstelle hierzu eine Zeichnung und erläutere.</div>

            <p>Wenn analoge Audio Signale aufgenommen, gespeichert und verarbeitet werden arbeitet man mit einer Abtastrate. Diese nimmt in bestimmten Abständen die Werte einer Frequenz auf. Bei dieser Abtastrate gibt es allerdings ein paar Dinge, die man
                beachten muss um keine essentiellen Daten zu verlieren. Dazu im Folgenden eine visualisierte Erklärung im Detail:</p>

            <img src="./pics/sampling_small.png" alt="kleine Abtastrate">


            <img src="./pics/sampling_large.png" alt="große Abtastrate">


            <img src="./pics/aliasing1.png" alt="Audio rekostruieren">

            <h4>Grenzfall Abtasttheorem</h4>
            <p>Das Abtasttheorem besagt, dass ein auf
                <div class="math">fmax</div> bandbegrenztes Signal aus einer Folge von äquidistanten Abtastwerten exakt rekonstruiert werden kann, wenn es mit einer Frequenz von größer als
                <div class="math">2 x fmax</div> abgetastet wurde.</p>
            <p>Wichtig ist also dass man mindestens 2 mal pro Frequenz den Ton abtastet um bei dem Rekonstruieren einer Audio Datei keine Inhalte zu verlieren.</p>


        </article>

        <article>
            <h3>
                <div class="list-indicator">2D</div> Vorbehandlung Audiosignal
            </h3>
            <div class="task-description">
                Bei herkömmlichen Soundkarten tritt systembedingt kein Aliasing auf, weil das Audiosignal stets geeignet vorbehandelt wird. Wie sieht diese Vorbehandlung aus?
            </div>
            <p>Soundkarten wenden auf eingehende Audiosignale einen low-pass filter an, der nur Frequenzen unter dem Aliasing-Grenzwert zulässt. Dadurch werden alle höheren Frequenzen, die ohne Vorbehandlung durch Aliasing verzerrt würden, herausgefiltert.
            </p>
        </article>

        <article>
            <h3>
                <div class="list-indicator">2E</div> Aliasing-Verzerrungen
            </h3>
            <div class="task-description">
                Modifiziere wave_io dahingehend, dass vom eingelesenen Audiosignal jeder zweite Abtastwert verworfen wird und das resultierende Signal abgespeichert wird. Der Header muss natürlich entsprechend verändert werden!
            </div>

            <p>Wir erzeugen ein neues Array, in das jeweils jeder zweite Wert der Originaldatei abgelegt wird, und schreiben dies in eine Datei.</p>

            <pre><code class="language-java">
				short[] downsampledAudio = new short[readWavFile.sound.length / 2 ];

				for (int i = 0; i &lt; samples; i+=2) {
						downsampledAudio[i/2] = readWavFile.sound[i];
				}

				WavFile.write_wav(outFilename, numChannels, numFrames/2, validBits, sampleRate/2, downsampledAudio);
			</code></pre>
            <p>

            </p>
        </article>

        <article>
            <h3>
                <div class="list-indicator">2F</div> Down-Sampling
            </h3>

            <div class="task-description">
                Wende das erstellte Programm auf die von mir geschickten Sinusdateien an (sine_hiXX.wav und sine_loXX.wav) an. Welche Frequenzen erscheinen nach dem Down-Sampling? Was würde passieren, wenn man geeignet bandbegrenzen würde?
            </div>

            <div class="aside">
                <div class="">
                    <img src="./pics/hi_downsampled.png" alt="the sinus_hi curve downsampled">
                </div>
                <div class="">
                    <h4>sine_hi</h4>
                    <p>Hier können wir sehen, dass aus den ursprünglichen 5,5kHz durch Aliasing 2,5kHz geworden ist.</p>
                </div>
            </div>

            <div class="aside">
                <div class="">
                    <img src="./pics/lo_downsampled.png" alt="the sinus_lo curve downsampled">
                </div>
                <div class="">
                    <h4>sine_lo</h4>
                    <p>Hier hat sich die Frequenz nicht verändert, da die Abtastrate noch hoch genug ist, um 2,5kHz ohne Aliasing aufzunehmen.</p>
                </div>
            </div>

            <h4>Was würde passieren, wenn man geeignet bandbegrenzen würde?</h4>
            <p>In diesem Fall würde der Ton verschwinden, da wir mit der Abtastfrequenz die hohen Töne nicht mehr bedienen könnten.
            </p>
        </article>

        <!--Aufgabe 3 A-->

        <article id="a3">
            <h2>Übung 1, Aufgabe 3: Bitreduzierung</h2>

            <h3>
                <div class="list-indicator">3A</div> PC-Soundkarten
            </h3>
            <div class="task-description">
                Die herkömmlichen PC-Soundkarten arbeiten meist entweder mit 16 oder 8 bit-Auflösung. Wie groß ist die Anzahl bei diesen beiden Werten darstellbaren Amplitudenwerten? </div>
            <p class="math">16 bit-Auflösung: 2^16=65536
            </p>
            <p class="math">8 bit-Auflösung: 2^8=256
            </p>
        </article>

        <!--Aufgabe 3 B-->

        <article>
            <h3>
                <div class="list-indicator">3B</div> Bitanzahl reduzieren
            </h3>
            <div class="task-description">
                Modifiziere wave_io dahingehend, dass die Bitanzahl reduziert wird. Dazu werden alle Samples durch eine Potenz von 2 geteilt (Integer-Division ohne Rest). Damit das resultierende Signal nicht leiser wird als das Original, wird die Operation durch Multiplikation
                mit derselben 2er Potenz kompensiert. Zu beachten: Der Datentyp hat nach wie vor 16 bit!
            </div>

            <pre><code class="language-java">
				// 3b Bitreduzierung
				short reduced_bits = 13;
				int divideBy = (int) Math.pow(2, reduced_bits);
				
				for (int i = 0; i &lt; samples; i++) {
					readWavFile.sound[i] = (short) ((short) (readWavFile.sound[i] / divideBy) * divideBy);
				}
				WavFile.write_wav(outFilename, numChannels, numFrames, validBits, sampleRate, readWavFile.sound);
	
			</code></pre>


        </article>

        <!--Aufgabe 3 C-->

        <article>
            <h3>
                <div class="list-indicator">3C</div> Wave-Dateien Bitanzahl hörbare Grenze der Qualität
            </h3>
            <div class="task-description">
                Mit dem entstandenen Programm sollen nun die in Aufgabe 1 erzeugten Wave-Dateien (Sprache und Musik) bitreduziert werden. Ab welcher Bitanzahl tritt eine hörbare, also deutliche Verschlechterung der Qualität ein? Bei wie viel Bit ist das Sprachsignal
                noch verständlich? </div>


            <div class="aside">
                <div class="">
                    <img src="./pics/A1_musik_04_bitreduced_8bit.png" alt="Musik Grenze der Qualität um 8 Bit reduziert">
                </div>
                <div class="">
                    <h4>Musik Grenze der Qualität (um 8 Bit reduziert) mit leichtem Rauschen:</h4>
                    <p>Ab einer Bitreduzierung von 8 Bit tritt eine hörbare Verschlechterung der Audioqualität des Musikstücks ein.</p>
                    <audio controls>
						<source src="./audio/A1_musik_04_bitreduced_8bit.wav" type="audio/wav">
					</audio>
                </div>
            </div>

            <div class="aside">
                <div class="">
                    <img src="./pics/A1_sprache_04_bitreduced_13.png" alt="Sprache Grenze der Qualität um 13 bit reduziert">
                </div>
                <div class="">
                    <h4>Sprache Grenze der Qualität (13 Bit reduziert), stark verzerrt:</h4>
                    <p>Ab einer Bitreduzierung von 13 Bit merkt man merklich wie die Qualität der Sprachaufnahme stark abnimmt.</p>
                    <audio controls>
						<source src="./audio/A1_sprache_04_bitreduced_13.wav" type="audio/wav">
					</audio>
                </div>
            </div>

            <div class="aside">
                <div class="">
                    <img src="./pics/A1_sprache_04_bitreduced_14.png" alt="Sprache Grenze der Verständlichkeit um 14 bit reduziert">
                </div>
                <div class="">
                    <h4>Sprache Grenze der Verständlichkeit (14 Bit reduziert), nicht mehr wirklich nachvollziehbar was gesagt wird:</h4>
                    <p>Ab einer Reduzierung der Audio Datei um 14 Bit wird es schwer den Sprecher zu verstehen und man kann nur noch in Grundzügen erahnen, was er sagt.</p>
                    <audio controls>
						<source src="./audio/A1_sprache_04_bitreduced_14.wav" type="audio/wav">
					</audio>
                </div>
            </div>

        </article>

        <!--Aufgabe 3 D-->

        <article>
            <h3>
                <div class="list-indicator">3D</div> Charaktereigenschaften Quantisierungsgeräusche
            </h3>
            <div class="task-description">
                Was charakterisiert das entstehende Quantisierungsgeräusch bei der Bitreduzierung und macht es besonders störend? </div>
            <p>Durch das Quantisieren schleicht sich ein Rauschen in das Audiosignal ein, welches die Qualität der Aufnahme sehr stark stört.
            </p>
        </article>

        <!--Aufgabe 3 E-->

        <article>
            <h3><div class="list-indicator">3E</div> Differenzsignal</h3>
            <div class="task-description">
                Modifiziere dein Programm noch einmal so, dass auch das Differenzsignal zwischen Original und bitreduziertem Signal, d.h. der Quantisierungsfehler ausgegeben werden kann. Dabei musst du bedenken, dass z.B. bei der 1 Bit Reduzierung das Quantisierungsrauschen
                nur von -1 bis +1 verlaufen würde. Dieser Wertebereich wäre viel zu klein, als dass man das Rauschen beim Abspielen als 16bit-Wert noch hören könnte. Daher muss das Rauschen durch Multiplikation mit einer 2er Potenz verstärkt werden. In
                anderen Worten: Hat man vorher durch 2^n geteilt, sollte man das Differenzsignal vor dem Abspeichern mit 2^(16-n-1) multiplizieren. So ist sichergestellt, dass der Verstärkungsfaktor mit der Anzahl der gelöschten Bits kleiner wird. </div>

            <h4>Der Code für die Aufgabe:</h4>
            <p>Hier muss wiederholt in (short) gecastet werden, da Division und Multiplikation int-Werte zurückgeben</p>
			<pre><code class="language-java">
				// 3e Bitreduzierung Differenz
	
				short[] difference = new short[readWavFile.sound.length];
	
				for (int i = 0; i &lt; samples; i++) {
					difference[i] = (short) (readWavFile.sound[i] - reducedSamples[i]);
					difference[i] = (short) (difference[i] * Math.pow(2, 16 - reduced_bits  -1));
				}
	
				WavFile.write_wav("modified-difference.wav", numChannels, numFrames, validBits, sampleRate, difference);	
			</code></pre>

            <h4>Die Differenz bei einer 1 bit-Reduzierung:</h4>

            <div class="aside">
                <div class="">
                    <img src="./pics/A1_musik_04_bitreduced_1bit_difference.png" alt="Musik - 1 Bit Differenz">
                </div>
                <div class="">
                    <h4>Musik - 1 Bit Differenz:</h4>
                    <p>Sehr starkes rauschen, das Grundsignal ist aber trotzdem hörbar.</p>
                    <audio controls>
						<source src="./audio/A1_musik_04_bitreduced_1bit_difference.wav" type="audio/wav">
					</audio>
                </div>
            </div>

            <div class="aside">
                <div class="">
                    <img src="./pics/A1_sprache_04_bitreduced_1_difference.png" alt="Sprache - 1 Bit Differenz">
                </div>
                <div class="">
                    <h4>Sprache - 1 Bit Differenz:</h4>
                    <p>Das Ursprungssignal ist nicht zu verstehen.</p>
                    <audio controls>
						<source src="./audio/A1_sprache_04_bitreduced_1_difference.wav" type="audio/wav">
					</audio>
                </div>
            </div>

            <h4>Differenz bei den hörbaren Quantisierungsfehlern:</h4>

            <div class="aside">
                <div class="">
                    <img src="./pics/A1_musik_04_bitreduced_8bit_difference.png" alt="Musik - 8 Bit Differenz">
                </div>
                <div class="">
                    <h4>Musik - 8 Bit Differenz:</h4>
                    <p>Das Ursprungssignal ist deutlich wahrnehmbar.</p>
                    <audio controls>
						<source src="./audio/A1_musik_04_bitreduced_8bit_difference.wav" type="audio/wav">
					</audio>
                </div>
            </div>

            <div class="aside">
                <div class="">
                    <img src="./pics/A1_sprache_04_bitreduced_13_difference.png" alt="Sprache - 13 Bit Differenz">
                </div>
                <div class="">
                    <h4>Sprache - 13 Bit Differenz:</h4>
                    <p>Da so stark reduziert wurde, ist das Differenzsignal wieder hochauflösender als das reduzierte Signal. </p>
                    <audio controls>
						<source src="./audio/A1_sprache_04_bitreduced_13_difference.wav" type="audio/wav">
					</audio>
                </div>
            </div>

        </article>

        <!--Aufgabe 3 F-->

        <article>
            <h3>
                <div class="list-indicator">3F</div> Charakter des Rauschen
            </h3>
            <div class="task-description">
                Welchen Charakter hat das Rauschen bei einer Reduktion um 1bit und wie verändert es sich bei zunehmender Bit-Reduktion? </div>
            <p>Das Rauschen ist wird von sanft und unauffällig steigernd immer lauter und kratziger und nimmt mehr und mehr Elemente des Originaltons mit sich.
            </p>
        </article>

    </div>
    <script src="./prism/prism.js"></script>
</body>

</html>